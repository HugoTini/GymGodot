{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GymGodot CartPole Example\n",
    "\n",
    "## Godot Environment\n",
    "\n",
    "Turn a Godot program into a Gym Environment with the following steps :\n",
    "\n",
    "\n",
    "   - **1)** create a Godot node (called `Env` in this CartPole example) that implements the following methods :\n",
    "\n",
    "        - **`func apply_action(action : Array) -> void`** : this method receives the action to execute in an array. For instance, it can be a single Int `[2]` if the actions belong to a `Discrete` space or it can be Floats `[2.3, 3.4]` if they belong to a continuous `Box` space. In this CartPole example, we can get two possible discrete actions : `[0]` (go left) or `[1]` (go right)\n",
    "\n",
    "        - **`func get_observation() -> Array`** : this method should return the current observable states in an array. In this CartPole example, we observe : Cart z-Position, Cart z-Velocity, Pole Angle and Pole Angle Velocity. Thus, we return an array of four floats.\n",
    "\n",
    "        - **`func get_reward() -> float`** : this method should return the current reward as a float. In this CartPole example, the reward is simple: we earn +1 at each step (we want to encourage the agent to survive as long as possible). In other environments, the reward could be more complex.\n",
    "\n",
    "        - **`func reset() -> void`** : this function resets the environment and makes it ready for a new episode. This often involves reinitializing the agent position, speed, etc. In this CartPole example, we reset the cart position to the middle of the screen and the pendulum to a vertical position.\n",
    "        \n",
    "        - **`func is_done() -> bool`** : this function should return `True` when the episode ends and `False` otherwise. Episode termination can be due to various events : the agent 'dies', goes out of a defined area, has too much error, lost the game, etc. In this CartPole example, the episode ends if the pendulum angle is more than $ \\Pi /8 $ rads from the vertical (because then we know it would be hard to keep balance, so better stop now and retry) or if the cart goes out of screen. It can also be used to put a time limit i.e. end the episode after `n` steps altough this can also be done on the Python side instead.\n",
    "        \n",
    "        \n",
    "  - **2)** add the `GymGodot` node (`GymGodot.tscn`) : add `GymGodot.tscn`, `GymGodot.gd` and `WebSocketClient.gd` from `/gym-godot` to your Godot project folder. Then drag & drop the `GymGodot.tscn` node in your scene. The `Environment Node` property of the `GymGodot` node must point to your `Env` node described above.\n",
    "  \n",
    "![nodes](./notebook_images/screenshot_godot.png)\n",
    "\n",
    "The `Step Length` property indicates how many Godot frames are run at each step. The action of the current step will be applied during all those frames. The minimum value for this property is 1, in which case one Godot frame = one step.\n",
    "\n",
    "When the scene is launched, it will look for the python server. If the server is not found, the program will close. To launch the scene without looking for the server, either delete the `GymGodot` node or disable its `Enabled` property.\n",
    "\n",
    "In this notebook, we'll use the demo Godot CartPole environment which has all of the above already setup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python / Gym Environment\n",
    "\n",
    "Once we have a Godot environment ready, we can start writing the Python learning script. First, we import Gym (which can be installed with `pip install gym`) and Numpy :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Godot environment will be exposed through the `server-v0` Gym environment provided in the GymGodot repo. This environment communicates over websocket with the `GymGodot` node. \n",
    "\n",
    "To install this Gym environment, open a terminal _**inside the GymGodot repo**_ and execute `pip install -e gym-server`. You should then be able to import it :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import gym_server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to configure this GymGodot server environment :\n",
    "\n",
    "\n",
    "- **`serverIP`**, **`serverPort`** : the (websocket) IP/port to use for communication.\n",
    "\n",
    "\n",
    "- **`exeCmd`** : the command to start the Godot environment. There are two possible ways :\n",
    "    - **Through Godot Editor**. Depending on the OS and how Godot was installed, the command can take different forms. For instance, on Linux with Godot installed through Flatpak, we can start Godot with : `flatpak run org.godotengine.Godot`. If you downloaded Godot directly without any package/app manager, it would be: `<path_to_godot_folder>/bin/godot.x11.tools.64`. We will have to execute from the project folder (i.e. the folder containing the `project.godot` file) and pass the path to the scene to execute (`./examples/pendulum/Root.tscn` for our Cartpole example here)\n",
    "    - Or, **export as an executable** (`Project -> Export` in Godot Editor). Then simply indicate the path to that executable in `exeCmd` (it must be re-exported if the scene is modified).\n",
    "\n",
    "\n",
    "- **`action_space`** : A Gym space for the action space of your environment, can be a continuous `Box` space or a discrete `Discrete` space. In this CartPole example, our action space is \"go left\" or \"go right\" i.e. a `Discrete` space which can take two values `0` or `1`.\n",
    "\n",
    "\n",
    "- **`observation_space`** : A Gym space for the action space of your environment. In this CartPole example, we observe four float values : Cart Position, Cart Velocity, Pole Angle and Pole Angle Velocity.\n",
    "\n",
    "\n",
    "- **`window_render`** : If `True` the environment will be rendered in the Godot window which can be useful for debugging. If `False`, rendering will be skipped which considerably speeds up the training.\n",
    "\n",
    "\n",
    "- **`render_path`** : Path where rendered frames will be stored. A frame is saved when calling `env.render()`. **The path must exist** (it will not create the corresponding folder if it doesn't exist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Server\n",
    "serverIP = '127.0.0.1'\n",
    "serverPort = '8000'\n",
    "\n",
    "# Godot game exe command\n",
    "projectPath = os.getcwd()[:-17] # '/home/user/.../GymGodot/gym-godot/' (project.godot folder)\n",
    "godotPath = 'flatpak run org.godotengine.Godot'\n",
    "scenePath = './examples/cartpole/Root.tscn'\n",
    "exeCmd = 'cd {} && {} {}'.format(projectPath, godotPath, scenePath)\n",
    "\n",
    "# Action Space ('go left' (0) or 'go right' (1))\n",
    "action_space = spaces.Discrete(2)\n",
    "\n",
    "# Observation Space (Cart Position, Cart Velocity, Pole Angle, Pole Angle Velocity)\n",
    "observation_space = spaces.Box(low=np.array([-40, -np.inf, -np.pi/8, -np.inf], dtype=np.float32), \n",
    "                               high=np.array([40, np.inf, np.pi/8, np.inf], dtype=np.float32),\n",
    "                               dtype=np.float32)\n",
    "\n",
    "# Create folder to store renders\n",
    "renderPath = os.getcwd() + '/render_frames/' # '/home/user/.../GymGodot/gym-godot/examples/cartpole/render_frames'\n",
    "if not os.path.exists(renderPath):\n",
    "    os.makedirs(renderPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up gym-server with those parameters\n",
    "env = gym.make('server-v0', serverIP=serverIP, serverPort=serverPort, exeCmd=exeCmd, \n",
    "               action_space=action_space, observation_space=observation_space, \n",
    "               window_render=True, renderPath=renderPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A window should open with the cartpole. Now we can control this environment from Python, let's do 5 steps with action \"go left\" :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    print(env.step(0)) # \"go left\"\n",
    "    # or env.step(1) for \"go right\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cart should start to go slightly on the left. This function returns the tuple : (`next_state`, `reward`, `done`, `info`) where `next_state` is our observation (i.e. the `[Cart z-Position, Cart z-Velocity, Pole Angle, Pole Angle Velocity]` in this example).\n",
    "\n",
    "We can re-initialize the environment :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "print(env.reset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the cart should be back into the middle of the screen with the pendulum vertical. This function returns the initial state (initial observation).\n",
    "\n",
    "We can also make a render of the environment :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The render will be saved at the `renderPath` folder path we configured above. We can display it here :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread(renderPath + '0.png')\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last, we can close our environment when we are done (the Godot window should be closing):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()\n",
    "del env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can implement the training algorithm on our own (using for e.g. PyTorch, Tensorflow, Keras, etc.) or we can use already existing RL libraries such as [Stable-Baseline 3](https://github.com/DLR-RM/stable-baselines3).\n",
    "\n",
    "We disable window rendering in our environment (`window_render=False`) to speed up computations but we can still render episodes manually using `env.render()`. This CartPole environment does not have a time limit (i.e. a max number of steps per episode) defined on Godot side but we can add such a limit from Python using Gym's `TimeLimit` wrapper. We set the limit to 250 steps and as we get +1 reward per step, this is also the maximum reward we can get.\n",
    "\n",
    "For this example we'll use Stable-Baseline (`pip install stable-baselines3`). We can follow the training progression from Tensorboard thanks to the `Monitor` wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "from gym.wrappers import TimeLimit\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "\n",
    "env = gym.make('server-v0', serverIP=serverIP, serverPort=serverPort, exeCmd=exeCmd, \n",
    "               action_space=action_space, observation_space=observation_space, \n",
    "               window_render=False, renderPath=renderPath)\n",
    "\n",
    "env = Monitor(TimeLimit(env, max_episode_steps=250))\n",
    "\n",
    "model = PPO(MlpPolicy, env, verbose=0, learning_rate=0.0004, seed=0,\n",
    "            tensorboard_log=\"./tensorboard_logs/\", device='cpu')\n",
    "model.learn(total_timesteps=140000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In TensorBoard we can see the agent is converging towards the maximum reward as the training is progressing :\n",
    "    \n",
    "<img src=\"./notebook_images/tensorboard_plot.png\" width=\"900\">\n",
    "\n",
    "We can save the learned model to disk :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cartpole_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model from disk :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load('cartpole_model', device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also render one episode using the learned model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "for i in range(250):\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    env.render()\n",
    "    if done :\n",
    "        break\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert the rendered frames as video, for instance with `ffmpeg` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('cd {} && ffmpeg -framerate 30 -y -i %01d.png -vcodec libvpx video.webm'.format(renderPath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "    <video width='256' height='256' controls>\n",
    "        <source src='./render_frames/video.webm'>\n",
    "    </video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should obtain an animation with the cart balancing looking like so :\n",
    "\n",
    "![cart_balancing_gif](./notebook_images/output.gif)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nteract": {
   "version": "0.14.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
